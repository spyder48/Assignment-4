{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct as st\n",
    "import matplotlib.pyplot as Plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNet(X,Y,h,n, alpha, nob, ite): \n",
    "    batch_size = Y.shape[1]//nob\n",
    "    \n",
    "    \n",
    "    X = (X - X.min(axis = 0))/(X.max(axis = 0)-X.min(axis = 0))\n",
    " #Parameters for first layer\n",
    "    w1 = 2/np.sqrt(n)*np.random.randn(h, 784)\n",
    "    b1 = np.zeros((h,1))\n",
    " #Parameters for second layer\n",
    "    w2 = 2/np.sqrt(h)*np.random.randn(10, h)\n",
    "    b2 = np.zeros((10,1))\n",
    "    i = 0\n",
    "    while True:\n",
    "  #First Layer\n",
    "        for j in range(nob):\n",
    "            \n",
    "            #creating mini batches for faster optimization\n",
    "            X1 = X[:,j*batch_size:(j+1)*batch_size]\n",
    "            Y1 = Y[:,j*batch_size:(j+1)*batch_size]\n",
    "            z1 = np.dot(w1,X1) + b1 \n",
    "            a1 = np.where(z1>0, z1, 0.01*z1) #Leaky ReLU Activation Function for Layer 1\n",
    "    #Creating Batches\n",
    "            a1 = (a1 - a1.mean(axis = 0))/a1.std(axis = 0)   \n",
    "            #Second Layer\n",
    "            z2 = np.dot(w2, a1) + b2\n",
    "            a2 = 1/(1+ np.exp(-z2)) #Sigmoid Activation Function for Layer 2\n",
    "            \n",
    "    #Let us do backpropagation now\n",
    "    \n",
    "            dLda2 = (1/Y1.shape[1])*(a2 - Y1) \n",
    "            da2dz2 = a2*(1-a2)\n",
    "            dz2dw2 = a1\n",
    "            dz2db2 = np.ones((X1.shape[1],1)) \n",
    "            dz2da1 = w2\n",
    "            da1dz1 = np.where(a1<0, 0.01, 1)\n",
    "            dz1dw1 = X1\n",
    "            dz1db1 = np.ones((X1.shape[1], 1))\n",
    "            \n",
    "            dw2 = np.dot(dLda2*da2dz2, dz2dw2.T)\n",
    "            db2 = np.dot(dLda2*da2dz2, dz2db2)\n",
    "            #print(dw2.shape, db2.shape)\n",
    "            dw1 = np.dot(((np.dot(dz2da1.T, dLda2*da2dz2)))*da1dz1, dz1dw1.T)\n",
    "            db1 = np.dot(((np.dot(dz2da1.T, dLda2*da2dz2)))*da1dz1, dz1db1)\n",
    "            #print(dw1.shape, db1.shape)\n",
    "            \n",
    "    #Parameter Update\n",
    "            w2 = w2 - alpha*dw2\n",
    "            w1 = w1 - alpha*dw1\n",
    "            b2 = b2 - alpha*db2\n",
    "            b1 = b1 - alpha*db1\n",
    "        i+=1\n",
    "        z1 = np.dot(w1,X) + b1 \n",
    "        a1 = np.where(z1>0, z1, 0.01*z1) #Leaky ReLU Activation Function for Layer 1\n",
    "    #Batch Normalization\n",
    "        a1 = (a1 - a1.mean(axis = 0))/a1.std(axis = 0)   \n",
    "    #Second Layer\n",
    "        z2 = np.dot(w2, a1) + b2\n",
    "        a2 = 1/(1+ np.exp(-z2))\n",
    "        error = np.sum((a2 - Y)**2)\n",
    "        print(error, i)\n",
    "        Plt.scatter(i,error,color='red',label='loss')\n",
    "        if i == ite:\n",
    "            return w1, w2, b1, b2\n",
    "    Plt.title(\"Loss Optimization\")\n",
    "    Plt.xlabel(\"Iterations\")\n",
    "    Plt.ylabel(\"Loss\")\n",
    "    Plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Train data extraction\n",
    "\n",
    "filename = {'images' : '/home/ravish/Downloads/Assignment-4/train-images.idx3-ubyte' ,'labels' : '/home/ravish/Downloads/Assignment-4/train-labels.idx1-ubyte'}\n",
    "#reading images data\n",
    "train_imagesfile = open(filename['images'],'rb')\n",
    "magicimages = st.unpack('>4B',train_imagesfile.read(4))\n",
    "nImg = st.unpack('>I',train_imagesfile.read(4))[0] #num of images\n",
    "nR = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n",
    "nC = st.unpack('>I',train_imagesfile.read(4))[0] #num of column\n",
    "nBytesTotal = nImg*nR*nC*1 #since each pixel data is 1 byte\n",
    "images = 255 - np.asarray(st.unpack('>'+'B'*nBytesTotal,train_imagesfile.read(nBytesTotal))).reshape((nImg,nR*nC))\n",
    "#reading label data\n",
    "train_labelfile = open(filename['labels'],'rb')\n",
    "magiclabel = st.unpack('>4B',train_labelfile.read(4))\n",
    "nLabels = st.unpack('>I',train_labelfile.read(4))[0] #num of labels\n",
    "labels = np.asarray(st.unpack('>'+'B'*nLabels,train_labelfile.read(nLabels))).reshape((nLabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the labels matrix as a binary matrix\n",
    "labelsmatrix = np.zeros((nLabels, 10))\n",
    "for i in range(nLabels):\n",
    "    labelsmatrix[i][labels[i]] = 1\n",
    "    #Splitting data in to training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labelsmatrix, test_size=0.2, random_state = 2)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46257.3562681811 1\n",
      "46017.30391607946 2\n",
      "46162.06989553254 3\n",
      "42120.55661745667 4\n",
      "37060.0289907846 5\n",
      "37074.81071798948 6\n",
      "30817.876790074813 7\n",
      "21957.59988479812 8\n",
      "21900.49844630799 9\n",
      "19839.62365565397 10\n",
      "18726.41052344527 11\n",
      "13008.576104158126 12\n",
      "12912.629532945642 13\n",
      "13066.683089594755 14\n",
      "13101.854587106323 15\n",
      "11285.56546842295 16\n",
      "8647.514166080193 17\n",
      "10080.510650816172 18\n",
      "8032.312165233826 19\n",
      "7452.627783512462 20\n",
      "7189.2552480282875 21\n",
      "6956.931520578857 22\n",
      "6508.991870474002 23\n",
      "6035.133694127067 24\n",
      "5886.882913532079 25\n",
      "5546.908083814502 26\n",
      "5267.052556045003 27\n",
      "5073.247812904612 28\n",
      "5034.586425091065 29\n",
      "4916.589613908949 30\n",
      "4663.188746996084 31\n",
      "4528.41584416785 32\n",
      "4361.062198566244 33\n",
      "4301.605983166233 34\n",
      "4206.418227143421 35\n",
      "4077.9798233942597 36\n",
      "3951.90965991205 37\n",
      "3886.9723241341817 38\n",
      "3833.795056586379 39\n",
      "3840.5620063779747 40\n",
      "3783.772503478776 41\n",
      "3871.548460053018 42\n",
      "3754.5658992848644 43\n",
      "3627.10368354059 44\n",
      "3638.005726669953 45\n",
      "3613.201133842167 46\n",
      "3576.5151084140807 47\n",
      "3552.5494251626287 48\n",
      "3397.253698693651 49\n",
      "3386.555146768292 50\n",
      "3318.701752676871 51\n",
      "3334.634242271661 52\n",
      "3305.971014071077 53\n",
      "3245.7080705350195 54\n",
      "3394.526033473052 55\n",
      "3330.926892560176 56\n",
      "3201.8379838025676 57\n",
      "3203.3142660914987 58\n",
      "3179.2246655153385 59\n",
      "3102.1056340827467 60\n",
      "3024.839137728819 61\n",
      "3011.4097718385574 62\n",
      "3010.2140981019743 63\n",
      "2965.3422399182427 64\n",
      "3320.3410928110848 65\n",
      "3051.876502022356 66\n",
      "2914.168599400443 67\n",
      "3095.0739584942776 68\n",
      "3266.6036498193853 69\n",
      "2887.192356033841 70\n",
      "3180.89750124781 71\n",
      "2826.5261672856336 72\n",
      "2823.8934025432436 73\n",
      "2938.2469152582876 74\n",
      "2745.16101065113 75\n",
      "2651.1824853089265 76\n",
      "2651.6236159620557 77\n",
      "2595.9961555807945 78\n",
      "2573.9230534599737 79\n",
      "2563.742830901242 80\n",
      "2544.9001786696663 81\n",
      "2530.1517959998096 82\n",
      "2523.0308152885095 83\n",
      "2505.516989288299 84\n",
      "2491.0316388716997 85\n",
      "2502.617327716786 86\n",
      "2449.1865091826285 87\n",
      "2433.833132106079 88\n",
      "2422.7473530493257 89\n",
      "2449.272031183646 90\n",
      "2418.4609932165185 91\n",
      "2384.2677589941177 92\n",
      "2420.3716192963566 93\n",
      "2376.701666645208 94\n",
      "2364.982926829287 95\n",
      "2390.176545964237 96\n",
      "2388.294899355602 97\n",
      "2352.5313137921194 98\n",
      "2354.80711295301 99\n",
      "2298.902029372658 100\n",
      "2291.1790107181596 101\n",
      "2265.121947377104 102\n",
      "2272.5537904328244 103\n",
      "2335.4858504898584 104\n",
      "2260.368718766966 105\n",
      "2234.6948144370053 106\n",
      "2203.4165758674058 107\n",
      "2219.1222102046518 108\n",
      "2206.1736334340276 109\n",
      "2200.0920567493085 110\n",
      "2217.938728061914 111\n",
      "2159.175826093697 112\n",
      "2148.049833891156 113\n",
      "2130.336821604718 114\n",
      "2116.3993436414194 115\n",
      "2106.083516594064 116\n",
      "2096.6024060797695 117\n",
      "2088.5048258360093 118\n",
      "2076.7781417389347 119\n",
      "2042.045094021931 120\n",
      "2047.9103512678307 121\n",
      "2029.6695453150433 122\n",
      "2022.8875157178752 123\n",
      "2022.4934045205189 124\n",
      "2024.6123054270772 125\n",
      "1989.6671706072425 126\n",
      "1985.532394772111 127\n",
      "1977.9265493997348 128\n",
      "1972.0344849888022 129\n",
      "1962.6896788472086 130\n",
      "1947.3805127718133 131\n",
      "1936.6507226208596 132\n",
      "1926.265438664951 133\n",
      "1913.255451871067 134\n",
      "1943.824114592362 135\n",
      "1889.9541272330118 136\n",
      "1885.9512424795578 137\n",
      "1884.6291526666225 138\n",
      "1895.9221242008155 139\n",
      "1858.3238003365484 140\n",
      "1872.7894070220098 141\n",
      "1868.7008552926927 142\n",
      "1831.1939836030704 143\n",
      "1820.325635820635 144\n",
      "1833.5646121807083 145\n",
      "1890.15028998749 146\n",
      "1800.0747456414967 147\n",
      "1830.9655367799849 148\n",
      "1818.0493392028486 149\n",
      "1786.3356155304612 150\n",
      "1789.5490414639278 151\n",
      "1759.4661018586437 152\n",
      "1736.9882583942072 153\n",
      "1740.0300614622654 154\n",
      "1732.797247904178 155\n",
      "1789.6894801399935 156\n",
      "1797.7159311572357 157\n",
      "1867.875844708576 158\n",
      "1696.2633923298383 159\n",
      "1731.4123009984849 160\n",
      "1688.7649278434635 161\n",
      "1736.0313332888231 162\n",
      "1668.0763432973288 163\n",
      "1664.994766647215 164\n",
      "1669.066647091578 165\n",
      "1662.611763625093 166\n",
      "1662.7215336770994 167\n",
      "1654.778520558977 168\n",
      "1628.3807421075737 169\n",
      "1685.6387707217887 170\n",
      "1676.0761775676547 171\n",
      "1701.1436713449539 172\n",
      "1679.9539052959005 173\n",
      "1746.076732946202 174\n",
      "1629.9828040979191 175\n",
      "1642.2496574367376 176\n",
      "1650.922096692648 177\n",
      "1671.8807074259396 178\n",
      "1776.2753713064646 179\n",
      "1568.8074286763974 180\n",
      "1591.1515827130993 181\n",
      "1580.4238700352985 182\n",
      "1628.1987994711649 183\n",
      "1565.526473365494 184\n",
      "1582.4657204149075 185\n",
      "1595.1529122053523 186\n",
      "1571.7937389585732 187\n",
      "1664.23992880384 188\n",
      "1601.7928509557378 189\n",
      "1588.328523686934 190\n",
      "1636.9147337509373 191\n",
      "1614.9035181677762 192\n",
      "1568.1277083389136 193\n",
      "1650.8943869544494 194\n",
      "1540.4465078824178 195\n",
      "1631.5552783777298 196\n",
      "1527.6154405937755 197\n",
      "1531.3634196244284 198\n",
      "1545.8664232636565 199\n",
      "1549.7862401878674 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Passing in arguments\n",
    "w1, w2, b1, b2 = NeuralNet(X_train, y_train, 200, 784, .5, 96, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 96.95833333333333\n"
     ]
    }
   ],
   "source": [
    "#For accuracy calculation on validation set\n",
    "X_test=(X_test-X_test.min(axis=0))/(X_test.max(axis=0)-X_test.min(axis=0))\n",
    "z1 = np.dot(w1,X_test) + b1 \n",
    "a1 = np.where(z1>0, z1, 0.01*z1) #Leaky ReLU Activation Function for Layer 1\n",
    "a1 = (a1 - a1.mean(axis = 0))/a1.std(axis = 0)            \n",
    "z2 = np.dot(w2, a1) + b2\n",
    "a2 = 1/(1+ np.exp(-z2)) #Sigmoid Activation Function for Layer 2\n",
    "\n",
    "k=0\n",
    "m1 = np.max(a2, axis = 0)\n",
    "m2 = np.max(a2*y_test, axis = 0)\n",
    "for i in range(y_test.shape[1]):\n",
    "    if m1[i]==m2[i]:\n",
    "        k+=1\n",
    "        \n",
    "print(\"Accuracy is:\", k*100/y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting of text data\n",
    "\n",
    "filename = {'images1' : '/home/ravish/Downloads/Assignment-4/t10k-images.idx3-ubyte' ,'labels1' : '/home/ravish/Downloads/Assignment-4/t10k-labels.idx1-ubyte'}\n",
    "#reading images data\n",
    "test_imagesfile = open(filename['images1'],'rb')\n",
    "magicimages = st.unpack('>4B',test_imagesfile.read(4))\n",
    "nImg = st.unpack('>I',test_imagesfile.read(4))[0] #num of images\n",
    "nR = st.unpack('>I',test_imagesfile.read(4))[0] #num of rows\n",
    "nC = st.unpack('>I',test_imagesfile.read(4))[0] #num of column\n",
    "nBytesTotal = nImg*nR*nC*1 #since each pixel data is 1 byte\n",
    "images1= 255 - np.asarray(st.unpack('>'+'B'*nBytesTotal,test_imagesfile.read(nBytesTotal))).reshape((nImg,nR*nC))\n",
    "#reading label data\n",
    "test_labelfile = open(filename['labels1'],'rb')\n",
    "magiclabel = st.unpack('>4B',test_labelfile.read(4))\n",
    "nLabels = st.unpack('>I',test_labelfile.read(4))[0] #num of labels\n",
    "labels1= np.asarray(st.unpack('>'+'B'*nLabels,test_labelfile.read(nLabels))).reshape((nLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the labels matrix as binary matrix\n",
    "labelsmatrix1 = np.zeros((nLabels, 10))\n",
    "for i in range(nLabels):\n",
    "    labelsmatrix1[i][labels1[i]] = 1  \n",
    "images1=images1.T\n",
    "labelsmatrix1 = labelsmatrix1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 97.21\n"
     ]
    }
   ],
   "source": [
    "#For accuracy calculation on test set data\n",
    "images1=(images1-images1.min(axis=0))/(images1.max(axis=0)-images1.min(axis=0))\n",
    "z1 = np.dot(w1,images1) + b1 \n",
    "a1 = np.where(z1>0, z1, 0.01*z1) #Leaky ReLU Activation Function for Layer 1\n",
    "a1 = (a1 - a1.mean(axis = 0))/a1.std(axis = 0)            \n",
    "z2 = np.dot(w2, a1) + b2\n",
    "a2 = 1/(1+ np.exp(-z2)) #Sigmoid Activation Function for Layer 2\n",
    "\n",
    "k=0\n",
    "m1 = np.max(a2, axis = 0)\n",
    "m2 = np.max(a2*labelsmatrix1, axis = 0)\n",
    "for i in range(labelsmatrix1.shape[1]):\n",
    "    if m1[i]==m2[i]:\n",
    "        k+=1\n",
    "        \n",
    "print(\"Accuracy is:\", k*100/labelsmatrix1.shape[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
